# SpaceX ETL Pipeline

This project implements an **ETL (Extract, Transform, Load)** process using SpaceX data. It collects data from the SpaceX API about rockets and rocket launches. This data is processed through three storage layers (**Bronze**, **Silver** and **Gold**) and prepared for analysis.

---

## ğŸ“ Project Structure

```
spacex_data_pipeline_ETL/
â”œâ”€â”€ delta_lake_data/
â”‚    â”œâ”€â”€ bronze/   # Raw data from APIs
â”‚    â”œâ”€â”€ silver/   # Cleaned and processed data
â”‚    â””â”€â”€ gold/     # Final, enriched dataset
â”‚
â”œâ”€â”€ scripts/
â”‚    â”œâ”€â”€ extract.py   # Handles data extraction
â”‚    â”œâ”€â”€ transform.py # Cleans and transforms the data
â”‚    â””â”€â”€ load.py      # Loads data into Delta Lake format
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Requirements

- Python 3.x
- Visual Studio Code (or any IDE)

Ensure you have **Python** installed:
```bash
python --version
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/matiasgarcia-dot/data_engineering_projects.git
cd data_engineering_projects/spacex_data_pipeline_ETL
```

### 2. Create a Virtual Environment (Optional but Recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Execute the ETL Process

1. **Extract Data:**
```bash
python scripts/extract.py
```

2. **Transform Data:**
```bash
python scripts/transform.py
```

3. **Load Data:**
```bash
python scripts/load.py
```

---

## ğŸŒ APIs Used

- **Rockets Data:** [`https://api.spacexdata.com/v4/rockets`](https://api.spacexdata.com/v4/rockets)
- **Launches Data:** [`https://api.spacexdata.com/v4/launches`](https://api.spacexdata.com/v4/launches)

---

## ğŸ“Œ Notes

- Data is stored in **JSON** format across the Bronze, Silver, and Gold layers.
- Ensure the `delta_lake_data` directory exists before running the scripts.

---





