# Data Engineering Projects

Welcome to my **Data Engineering Projects** repository! üöÄ Here, you'll find practical examples of ETL pipelines, data transformations, and various data workflows using Python and cutting-edge technologies.

---

## üìä Projects

### 1. SpaceX Data Pipeline (ETL)
- **Description:** Extracts data from SpaceX APIs about rockets and their launches and processes them through the Bronze, Silver and Gold layers.
- **Technologies:** Python, Delta Lake, REST API
- **Folder:** [`spacex_data_pipeline_ETL`](./spacex_data_pipeline_ETL)

### 2. ETL Analysis with PySpark
- **Description:** Implements an ETL pipeline using **PySpark** for data analysis on the best-selling car brands and the most used transmission type in a certain location on a large scale.
- **Technologies:** Python, PySpark
- **Folder:** [`ETL_Analytics_with_PySpark`](./ETL_Analytics_with_PySpark)

### 3. Country risk ETL
- **Description:** Processes country risk data, cleaning and storing it for analysis.
- **Technologies:** Python, Pandas, API
- **Folder:** [`country_risk_ETL`](./country_risk_ETL)

### 3. Clean Data MySQL
- **Description:** Import CSV, cleaned, optimize and export to clean database Employ's company.
- **Technologies:** MySQL Workbench and CSV.
- **Folder:** [`Clean_Data_MySQL`](./Clean_Data_MySQL)

### 4. Python_Game_Space_Invaders
- **Description:** A customized version of the classic Space Invaders, developed as a group academic project for the Programming Technician program (UTN San Rafael). I participated in the development of the game's main loop and the basic level layout, with support from peers and technical assistance.
- **Technologies:** Python 3, Pygame, SQLite, Git, GitHub.
- **Folder:** [`Space-Invaders-UTN`]
- **Proyect Video:** https://drive.google.com/file/d/1MJLILGkoGaGpMZW0b_3PS-NrMR8TpJsg/view?usp=drive_link
---

## üõ†Ô∏è Technologies Used
- **Python 3.x**
- **PySpark**
- **MySQL Workbench**
- **SQLite**
- **PyGame**
- **CSV**
- **Delta Lake**
- **API**
- **REST APIs**
- **Pandas**
- **Power Bi**
- **Google Colaboratory**
- **Request**
    
---

## üìå How to Run the Projects

1. Clone the repository:
   ```bash
   git clone https://github.com/matiasgarcia-dot/data_engineering_projects.git
   cd data_engineering_projects
   ```

2. Create a virtual environment (optional but recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: .\venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Navigate to the desired project folder and execute the scripts following the README inside each project.

---

## üìà Future Plans
- Add data pipelines using **Apache Airflow**
- Implement real-time data streaming with **Kafka**
- Explore more APIs and external datasets

---

---

## üìß Contact
- **Author:** Matias Garcia 
- **GitHub:** [matiasgarcia-dot](https://github.com/matiasgarcia-dot)

