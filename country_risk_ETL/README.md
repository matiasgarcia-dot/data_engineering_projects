# ETL Project: Argentina Risk Analysis
This project implements a simple ETL (Extract, Transform, Load) pipeline to analyze Argentina's 
financial risk index using data from a public API. The extracted data is cleaned, transformed, and 
stored in a local SQLite database for further analysis.

## Technologies Used
- Python 3.x
- Pandas
- Requests
- SQLite
- Power BI

## Project Structure

```
.
├── extract.py        # Script to fetch data from the API
├── transform.py      # Script to clean and transform the data
├── load.py           # Script to load data into a SQLite database
├── transformed_data.csv  # CSV file with the transformed data
├── risk_analysis.db  # SQLite database file
├── Graphical Display  # Folder containing data visualizations in PDF and Power BI formats
│   ├── visualization.pdf
│   └── visualization.pbix
└── README.md         # Project documentation
```

## Setup Instructions

1. Clone this repository.
2. Ensure you have Python 3.x installed.
3. Install the required dependencies:
   ```bash
   pip install pandas requests
   ```
4. Run each script in sequence:
   ```bash
   python extract.py
   python transform.py
   python load.py
   ```

## ETL Pipeline Breakdown

### 1. Extract

**Script:** `extract.py`
This script fetches Argentina's financial risk index data from the API endpoint:

```
https://api.argentinadatos.com/v1/finanzas/indices/riesgo-pais
```
If the request is successful, the data is converted to a Pandas DataFrame and displayed.

### 2. Transform

**Script:** `transform.py`
This script cleans and transforms the data to ensure it is ready for analysis.

#### Key Transformation Steps:

- Rename columns for clarity (`risk_value`, `date`)
- Convert the `date` column to datetime format
- Sort data by date
- Calculate daily variations and percentage changes in the risk value
- Add a `trend` column indicating whether the risk increased, decreased, or remained unchanged
- Remove any null values generated by calculations
- Save the transformed data to `transformed_data.csv`

### 3. Load

**Script:** `load.py`
This script loads the transformed data into a local SQLite database (`risk_analysis.db`).

#### Key Loading Steps:

- Connect to (or create) the SQLite database
- Create a table (`risk_data`) if it does not already exist
- Insert data from the CSV file into the database
- Verify the data by printing sample rows

### 4. Visualization

The data was visualized in **Power BI**, displaying the processed information in a table format
for further analysis and insights.

The visualization outputs are available in the `Graphical Display` folder as:

- `visualization.pdf`: Static report of data visualizations
- `visualization.pbix`: Power BI project file

## Usage

To analyze the data, run the scripts sequentially as described above. After running `load.py`, you 
can query the SQLite database (`risk_analysis.db`) for insights.

## Sample Output

### Extracted Data (Sample)

```
   risk_value        date
0         1800 2025-01-01
1         1850 2025-01-02
```

### Transformed Data (Sample)

```
   risk_value       date  daily_variation  percent_change    trend
0         1800 2025-01-01              NaN              NaN  No Change
1         1850 2025-01-02             50.0        2.777778  Increase
```

### Loaded Data (Sample)

```
(1800, '2025-01-01', NULL, NULL, 'No Change')
(1850, '2025-01-02', 50.0, 2.777778, 'Increase')
```


